# Cognitive Checkpoint (CC) — Snapshot

**Date:** 2026-01-06
**Purpose:** 保存して脳のスタックを解放するためのスナップショット。後日読み戻して成熟させる。

---

## 1. 到達点（要約）
- **ローカルLLM協働**（Obsidian／テキストエディタ＋API）は、速度・依存度・文脈制御の点で想像以上に実用。
- **WebUI と API は“別のAI”**に見える：前者は冗長・迎合的、後者は低冗長・高集中（文房具的）。
- **人間をプロトコルに含める**設計が最も安定（CC/引継書で再開可能）。
- **万能化ではなく研ぎ澄まし**：常駐人格ではなく、単機能プロセスとしてのAI。

---

## 2. 重要な洞察
- **時制の誤解**：LLMはPCの日時を自動取得しない。OS統合は別技術。
- **意味論的DIFF**が編集体験を更新する鍵（多次元視点）。
- **Self-Polyの再定義**：語彙ブロック／語句選択UIを活かし、重い語彙チェインを排除した軽量実装がOSS的に可能。
- **家庭用AI GPU仮説**：性能よりVRAM。理想は“遅くて大容量”だが市場的に出にくい。

---

## 3. UI/運用の仮説（実装イメージ）
- **Windowsトレイ常駐の最小UI**：
  - 入力1行 → ローカルLLM APIへ送信
  - コンテキスト保持なし
  - 初期投入は **CC/引継書** のみ
  - 返答はポップアップ or クリップボード
- **.com実行ファイル的AI**：単機能・即起動・即終了・状態はテキスト外部化。

---

## 4. 実験ログ（要点）
- Obsidian + Copilot + ローカルLLM（LMStudio）で体感速度は十分。
- API経由の軽量利用は応答の“尖り”が出る。
- エディタマクロ移植は可（古いJSエンジン対応に注意）。

---

## 5. リスク/留意点
- コンテキスト自動収集は依存と混乱を生む。
- LLMを判断者にしない。最終判断は人間（または外部論理）。
- 市場論と技術論を混ぜない（Xでの“スパゲッティ化”に注意）。

---

## 6. 次の保留課題（未実装）
- 意味論的DIFFの可視化UI（テキスト俯瞰）。
- 語彙抽出→ブロック化の自動支援。
- トレイUIの最小実装（PoC）。

---

## 7. 解除宣言
このCCを保存した。**今は忘れてよい。**
再開時は本ドキュメントを初期プロンプトに投入する。

