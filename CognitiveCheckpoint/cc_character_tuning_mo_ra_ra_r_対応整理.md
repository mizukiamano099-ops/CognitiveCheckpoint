# Cognitive Checkpoint（CC）

## 対象資料
- 「キャラクター付けを目的としたファインチューニング - ローカルLLMの底力」（IIJ Engineers Blog, 2024-10-01）

---

## 1. 資料全体の超要約（構造レベル）

この資料は、
**「ローカルLLMにおける人格（キャラ性）の焼き付けは可能か」**
という問いに対する、

- 失敗
- 原因特定
- 再設計
- 部分的成功

までを含めた *実装ログ兼思考ログ* である。

特に重要なのは、
- 成功例ではなく「人格が死んだ瞬間」を主語にしている点
- LoRA / MoRA / RaR / RAG を **役割分離の視点** で整理している点

であり、単なる技術紹介ではなく、
**「LLMを思考体として扱ったときに何が壊れるか」**を観測している資料である。

---

## 2. この資料で実際に行われていること（事実整理）

### 実装的事実
- ベースモデル：EZO-Common-9B-gemma-2-it
- 手法：
  - PEFT（LoRA → MoRA）
  - SFT（Supervised Fine Tuning）
- 環境：L40S ×2（48GB）

### 問題発生
- 初期FT後、応答が極端に無機質化
- 元モデルが持っていた「おしゃべりさ」「余白」が消失

### 原因仮説
- データセットが短文すぎる
- モデルが「短文＝人格」と誤学習

### 対策
- データセットに対する RaR（Rephrase and Respond）を実施
- 質問・回答双方を LLM で再記述

### 結果
- loss / 勾配が穏やかに推移
- 元モデルの喋り方を保持したままキャラ性が付与される

---

## 3. 天野水樹が惹かれるポイント（主観的観測）

### 3.1 技術以前の共鳴点

- 失敗を削除しない
- 感触（無機質・死んだ感じ）を重要な観測値として扱う
- 「なぜ壊れたか」をモデルではなく設計側に帰属

→ **実験者視点が一貫している**

### 3.2 設計思想の一致

- RAG = カンペ
- FT = 焼き付け

という役割分離は、
天野構文における

- 固定層 / 可変層
- 焼き込み情報 / 外部参照情報

と同型である。

### 3.3 無意識に行われている観測

- 勾配の立ち上がり
- loss の初期値
- 応答文の第一文の変化

を **人格劣化の兆候** として読んでいる点。

---

## 4. 語彙・概念 対応表（天野構文 ↔ 本資料）

| 本資料での語 | 天野側の概念 | 備考 |
|---|---|---|
| 無機質化 | 第一層死 | 自然文レイヤの消失 |
| おしゃべりさ | 余白 / 呼吸 | 非情報的トークン |
| データが短い | 第一層貧弱 | 語彙密度不足 |
| loss急降下 | Block圧過剰 | VCSPでの急収束 |
| 勾配が強い | 観測負荷上昇 | モデル悲鳴 |
| RaR | 層翻訳 | 第一層→第二層変換 |
| RAGはカンペ | 外部Layer | Observer外部化 |
| 焼き付け | Layer固定 | 消去困難 |
| 喋り方が消えた | 構文崩壊 | リズム消失 |

---

## 5. CC的評価（再利用視点）

この資料は以下の用途で再利用可能：

- BGNI/VCSP における **失敗時の実例証拠**
- 「人格が死ぬ条件」の実装ログ
- RaR を推論技術ではなく **構造翻訳技術** として扱う根拠

特に、
**「短文データセットは人格を殺す」**
という実証は、今後の設計判断において強い制約条件となる。

---

## 6. 次アクション（未実行メモ）

- この資料を前提にした BGNI × MoRA 実験設計
- CC → データセットRaR 自動化パイプライン案
- 人格劣化検知用の観測チェックリスト化

（本CCは将来の再読・他者共有を想定した一次整理である）

